# build_vectorstore.py
from document_loader import load_documents_from_directory
from chunking import smart_split_documents
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
import os


def build_or_update_vectorstore(doc_dir: str, persist_dir: str = "./chroma_db"):
    """æ„å»ºæˆ–å¢é‡æ›´æ–°å‘é‡åº“"""
    # 1. åŠ è½½æ‰€æœ‰æ–‡æ¡£
    docs = load_documents_from_directory(doc_dir)

    # 2. æ™ºèƒ½åˆ†å—
    chunks = smart_split_documents(docs)

    # 3. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    embedding = HuggingFaceEmbeddings(
        model_name="BAAI/bge-small-zh-v1.5",
        model_kwargs={"device": "cpu"}
    )

    # 4. åˆ›å»ºæˆ–æ›´æ–°å‘é‡åº“
    if os.path.exists(persist_dir):
        print("ğŸ”„ æ›´æ–°ç°æœ‰å‘é‡åº“...")
        vectorstore = Chroma(
            persist_directory=persist_dir,
            embedding_function=embedding
        )
        # åˆ é™¤æ—§æ•°æ®ï¼ˆç®€å•æ–¹æ¡ˆï¼šé‡å»ºï¼›ç”Ÿäº§ç¯å¢ƒå¯ç”¨ delete(ids)ï¼‰
        # è¿™é‡Œä¸ºç®€åŒ–ï¼Œç›´æ¥é‡å»º
        import shutil
        shutil.rmtree(persist_dir)

    print("ğŸ†• åˆ›å»ºæ–°å‘é‡åº“...")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embedding,
        persist_directory=persist_dir
    )

    print(f"âœ… å‘é‡åº“æ„å»ºå®Œæˆï¼å…± {len(chunks)} ä¸ªç‰‡æ®µ")
    return vectorstore