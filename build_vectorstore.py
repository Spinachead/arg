from langchain_ollama import OllamaEmbeddings  # build_vectorstore.py
from document_loader import load_documents_from_directory
from chunking import smart_split_documents
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
import os

from utils import get_default_embedding


def build_or_update_vectorstore(doc_dir: str, persist_dir: str = "./chroma_db"):
    """æ„å»ºæˆ–å¢é‡æ›´æ–°å‘é‡åº“"""
    # 1. åŠ è½½æ‰€æœ‰æ–‡æ¡£
    docs = load_documents_from_directory(doc_dir)

    # 2. æ™ºèƒ½åˆ†å—
    chunks = smart_split_documents(docs)

    # 3. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    embedding = OllamaEmbeddings(
        model=get_default_embedding(),
        base_url="http://localhost:11434"
    )

    # 4. åˆ›å»ºæˆ–æ›´æ–°å‘é‡åº“
    if os.path.exists(persist_dir):
        print("ğŸ”„ æ›´æ–°ç°æœ‰å‘é‡åº“...")
        # æ­£ç¡®å…³é—­å¯èƒ½å­˜åœ¨çš„æ•°æ®åº“è¿æ¥
        vectorstore = Chroma(
            persist_directory=persist_dir,
            embedding_function=embedding
        )
        vectorstore.delete_collection()

    print("ğŸ†• åˆ›å»ºæ–°å‘é‡åº“...")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embedding,
        persist_directory=persist_dir
    )

    print(f"âœ… å‘é‡åº“æ„å»ºå®Œæˆï¼å…± {len(chunks)} ä¸ªç‰‡æ®µ")
    return vectorstore

if __name__ == "__main__":
    build_or_update_vectorstore("documents")